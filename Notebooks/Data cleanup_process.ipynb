{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb7ace7-7309-4697-820c-019f7abb2aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e513d4e-f1f3-40e4-879b-e49c697cd97a",
   "metadata": {},
   "source": [
    "## Cleanup airport hub data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82081b85-b6bf-4f37-9c79-01faa4d63105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "airport_hubs_path = 'airport hubs.csv'\n",
    "airports_cleaned_path = 'Airports_Cleaned.csv'\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "airport_hubs_df = pd.read_csv(airport_hubs_path)\n",
    "airports_cleaned_df = pd.read_csv(airports_cleaned_path)\n",
    "\n",
    "# Perform the join using 'Airport ID' from airport_hubs.csv and 'ARPT_ID' from Airports_Cleaned.csv\n",
    "merged_df = airport_hubs_df.merge(airports_cleaned_df, left_on='ARPT_ID', right_on='ARPT_ID', how='inner')\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['COUNTRY_CODE', 'OWNERSHIP_TYPE_CODE', 'FACILITY_USE_CODE', 'STATE_CODE' ]\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df744e16-8a81-4a97-bdb6-89bb7bb0448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data has been saved\n"
     ]
    }
   ],
   "source": [
    "# Save the output to a new CSV file\n",
    "merged_df.to_csv('../Final_Cleaned_Data/Airport_Hub_List.csv', index=False)\n",
    "\n",
    "# Display a message\n",
    "print(\"Merged data has been saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d1747-3b73-4134-b6d1-d267b99aa879",
   "metadata": {},
   "source": [
    "## Weather cleanup and data engineering processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7789cc5-ac97-47bf-94ad-486413e37a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weather csv files to include ARPT_ID column and populate with Airport ID\n",
    "# Path to the weather data directory\n",
    "weather_2023_directory = r'D:\\_Bootcamp\\_Project4\\Redo\\Weather\\W_2021'\n",
    "\n",
    "# Iterate through each CSV file in the Weather data directory\n",
    "for file in os.listdir(weather_2023_directory):\n",
    "    if file.endswith('.csv'):  # Process only CSV files\n",
    "        file_path = os.path.join(weather_2023_directory, file)\n",
    "        \n",
    "        # Extract the first 3 letters of the file name\n",
    "        arpt_id = file[:3]\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add the ARPT_ID column\n",
    "        df['ARPT_ID'] = arpt_id\n",
    "        \n",
    "        # Save the updated DataFrame back to the same file\n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "        print(f\"Updated file: {file} with ARPT_ID = {arpt_id}\")\n",
    "\n",
    "# Summary message\n",
    "print(\"All CSV files in the Weather_2023 directory have been updated with the ARPT_ID column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13dbf6-e183-4b5c-86f3-2b9cefa606d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for the CSV files\n",
    "weather_2019_directory = '\\Weather\\Weather_2019'\n",
    "weather_2020_directory = '\\Weather\\Weather_2020'\n",
    "weather_2021_directory = '\\Weather\\Weather_2021'\n",
    "weather_2022_directory = '\\Weather\\Weather_2022'\n",
    "weather_2023_directory = '\\Weather\\Weather_2023'\n",
    "weather_2024_directory = '\\Weather\\Weather_2024'\n",
    "output_file = '\\Weather\\Cleaned\\Merged_Weather.csv'\n",
    "\n",
    "# Combine all directories into a list\n",
    "directories = [weather_2019_directory, weather_2020_directory, weather_2021_directory, weather_2022_directory, weather_2023_directory, weather_2024_directory]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through each directory and process CSV files\n",
    "for directory in directories:\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv'):  # Process only CSV files\n",
    "            file_path = os.path.join(directory, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a single CSV file\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display a summary message\n",
    "print(f\"All CSV files from weather data have been merged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f5d282d-76dd-4625-99a5-437ce6765e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weather data with engineered features saved.\n"
     ]
    }
   ],
   "source": [
    "# Weather data engineering\n",
    "# Load the dataset\n",
    "file_path = '\\Weather\\Cleaned\\Merged_Weather.csv'\n",
    "weather_data = pd.read_csv(file_path)\n",
    "\n",
    "# Define thresholds for feature engineering\n",
    "extreme_heat_threshold = 49  # °C\n",
    "extreme_cold_threshold = -20  # °C\n",
    "severe_cold_threshold = -40  # °C\n",
    "strong_wind_speed_threshold_kmh = 46.3  # km/h (~25 knots)\n",
    "severe_wind_speed_threshold_kmh = 74.1  # km/h (~40 knots)\n",
    "heavy_precipitation_threshold = 10  # mm\n",
    "extreme_precipitation_threshold = 50  # mm\n",
    "\n",
    "# Create binary features for temperature thresholds\n",
    "weather_data['extreme_heat'] = weather_data['temperature_2m_max'] > extreme_heat_threshold\n",
    "weather_data['extreme_cold'] = weather_data['temperature_2m_min'] < extreme_cold_threshold\n",
    "weather_data['severe_cold'] = weather_data['temperature_2m_min'] < severe_cold_threshold\n",
    "\n",
    "# Create binary features for precipitation thresholds\n",
    "weather_data['light_precipitation'] = weather_data['precipitation_sum'] < heavy_precipitation_threshold\n",
    "weather_data['moderate_precipitation'] = (weather_data['precipitation_sum'] >= heavy_precipitation_threshold) & \\\n",
    "                                         (weather_data['precipitation_sum'] < extreme_precipitation_threshold)\n",
    "weather_data['heavy_precipitation'] = weather_data['precipitation_sum'] >= extreme_precipitation_threshold\n",
    "\n",
    "# Create binary feature for snowfall with freezing temperatures\n",
    "weather_data['freezing_precipitation'] = (weather_data['snowfall_sum'] > 0) & \\\n",
    "                                         (weather_data['temperature_2m_min'] <= 0)\n",
    "\n",
    "# Create binary features for wind speed thresholds (converted to km/h)\n",
    "weather_data['strong_winds'] = weather_data['wind_speed_10m_max'] * 3.6 > strong_wind_speed_threshold_kmh\n",
    "weather_data['severe_winds'] = weather_data['wind_gusts_10m_max'] * 3.6 > severe_wind_speed_threshold_kmh\n",
    "\n",
    "# Composite indicator: High likelihood of delay (any extreme condition met)\n",
    "weather_data['high_delay_likelihood'] = weather_data[\n",
    "    ['extreme_heat', 'extreme_cold', 'heavy_precipitation', 'severe_winds']\n",
    "].any(axis=1)\n",
    "\n",
    "# Save the updated dataset\n",
    "updated_file_path = '\\Weather\\Cleaned\\merge_w_data_engineered .csv'\n",
    "weather_data.to_csv(updated_file_path, index=False)\n",
    "\n",
    "print(f\"Updated weather data with engineered features saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c32801-5cdb-4d4c-a396-c2942bb2d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                            object\n",
      "latitude                       float64\n",
      "longitude                      float64\n",
      "weather_code                   float64\n",
      "temperature_2m_max             float64\n",
      "temperature_2m_min             float64\n",
      "precipitation_sum              float64\n",
      "snowfall_sum                   float64\n",
      "precipitation_hours            float64\n",
      "wind_speed_10m_max             float64\n",
      "wind_gusts_10m_max             float64\n",
      "wind_direction_10m_dominant    float64\n",
      "ARPT_ID                         object\n",
      "extreme_heat                      bool\n",
      "extreme_cold                      bool\n",
      "severe_cold                       bool\n",
      "light_precipitation               bool\n",
      "moderate_precipitation            bool\n",
      "heavy_precipitation               bool\n",
      "freezing_precipitation            bool\n",
      "strong_winds                      bool\n",
      "severe_winds                      bool\n",
      "high_delay_likelihood             bool\n",
      "id                             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display weather data csv data type\n",
    "weather_df = pd.read_csv('Merged_Weather_Data_Completed.csv') \n",
    "\n",
    "# Display data types of each column\n",
    "print(weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c0a7680-576e-416b-a50b-fac5926279f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "weather_df = pd.read_csv('Merged_Weather_Data_Completed.csv') \n",
    "\n",
    "# Change date format \n",
    "weather_df['date'] = pd.to_datetime(weather_df['date']).dt.strftime('%m/%d/%Y') \n",
    "\n",
    "# Export the modified DataFrame to a new CSV file\n",
    "weather_df.to_csv('Merged_Weather_Data_date.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56bbc323-5bbf-42e0-b20b-38a70c15db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. Updated file saved as: D:\\_Bootcamp\\_Project4\\Data\\Merged_Weather_Data_Completed_binary.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert boolean columns True = 1, False = 0\n",
    "# Path to the input CSV file\n",
    "input_file = 'Merged_Weather_Data_Completed.csv'\n",
    "\n",
    "# Path to the output CSV file\n",
    "output_file = 'Merged_Weather_Data_Completed_binary.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Convert True/False to 1/0 for all columns\n",
    "df = df.replace({True: 1, False: 0})\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Conversion complete. Updated file saved as: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe5893-e27b-4433-9289-8fa1ab8773b3",
   "metadata": {},
   "source": [
    "## Flight delay cleanup process and data engineering processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84744dc5-cbd2-4401-8cfe-0cc053d8ecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_1.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_10.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_11.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_12.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_2.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_3.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_4.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_5.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_6.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_7.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_8.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2022_9.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_1.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_10.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_11.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_12.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_2.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_3.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_4.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_5.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_6.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_7.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_8.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2023_9.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_1.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_2.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_3.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_4.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_5.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_6.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_7.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_8.zip...\n",
      "Extracting On_Time_Marketing_Carrier_On_Time_Performance_Beginning_January_2018_2024_9.zip...\n",
      "Extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# Extract flight delay zipped files to a folder\n",
    "# Function to extract all zipped files in a folder\n",
    "def extract_zipped_files(source_folder, target_folder):\n",
    "    # Create target folder if it doesn't exist\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "    \n",
    "    # Loop through files in the source folder\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        if file_name.endswith(\".zip\"):\n",
    "            file_path = os.path.join(source_folder, file_name)\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                print(f\"Extracting {file_name}...\")\n",
    "                zip_ref.extractall(target_folder)\n",
    "    \n",
    "    print(\"Extraction completed.\")\n",
    "\n",
    "# Specify the source folder containing the zip files\n",
    "source_folder = 'Project4\\_Archive\"\n",
    "\n",
    "# Specify the target folder where you want to extract the files\n",
    "target_folder = 'Flight_delays\\part1_csv\"\n",
    "\n",
    "# Run the function\n",
    "extract_zipped_files(source_folder, target_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f24840-e16c-41d5-9423-c42075a44d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_1.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_10.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_11.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_12.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_2.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_3.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_4.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_5.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_6.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_7.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_8.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_9.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_10.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_11.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_2.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_3.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_4.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_5.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_6.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_7.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_8.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_9.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_1.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_2.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_3.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_4.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_5.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_6.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_7.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_8.csv (kept specified columns)\n",
      "Processed file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_9.csv (kept specified columns)\n",
      "All CSV files in the Flight_Delays directory have been updated to retain only the specified columns.\n"
     ]
    }
   ],
   "source": [
    "# Remove unneeded columns in the flight delay data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Path to the Flight_Delays folder\n",
    "flight_delays_directory = 'Flight_delays\\part1_csv'\n",
    "\n",
    "# Columns to keep\n",
    "columns_to_keep = [\n",
    "    'Year', 'FlightDate', 'Operating_Airline ', 'Origin', \n",
    "    'OriginStateName', 'Dest', 'DestStateName', \n",
    "    'CRSDepTime', 'DepTime', 'DepDelay', 'DepDelayMinutes', \n",
    "    'CRSArrTime', 'ArrTime', 'ArrDelay', 'ArrDelayMinutes', \n",
    "    'Cancelled', 'CancellationCode', 'WeatherDelay', 'NASDelay',\n",
    "    'SecurityDelay', 'CarrierDelay', 'LateAircraftDelay'\n",
    "]\n",
    "\n",
    "# Iterate through each CSV file in the Flight_Delays directory\n",
    "for file in os.listdir(flight_delays_directory):\n",
    "    if file.endswith('.csv'):  # Process only CSV files\n",
    "        file_path = os.path.join(flight_delays_directory, file)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Keep only the specified columns, ignoring missing ones\n",
    "        filtered_df = df.loc[:, df.columns.intersection(columns_to_keep)]\n",
    "        \n",
    "        # Save the filtered DataFrame back to the same file\n",
    "        filtered_df.to_csv(file_path, index=False)\n",
    "        \n",
    "        print(f\"Processed file: {file} (kept specified columns)\")\n",
    "\n",
    "# Summary message\n",
    "print(\"All CSV files in the Flight_Delays directory have been updated to retain only the specified columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f9a883-1e6b-43cb-8c16-1fc98f671554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_1.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_1.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_10.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_10.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_11.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_11.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_12.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_12.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_2.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_2.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_3.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_3.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_4.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_4.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_5.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_5.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_6.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_6.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_7.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_7.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_8.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_8.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_9.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_9.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_10.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_10.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_11.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_11.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_2.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_2.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_3.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_3.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_4.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_4.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_5.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_5.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_6.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_6.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_7.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_7.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_8.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_8.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_9.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_9.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_1.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_1.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_2.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_2.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_3.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_3.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_4.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_4.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_5.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_5.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_6.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_6.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_7.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_7.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_8.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_8.csv)\n",
      "Filtered file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_9.csv (saved to D:\\_Bootcamp\\_Project4\\Redo\\Flight_delays\\csv\\output_matched_APRT\\On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_9.csv)\n",
      "All CSV files in the Flight_Delays directory have been filtered and saved.\n"
     ]
    }
   ],
   "source": [
    "# Keeping records that matched with target ARPT_ID\n",
    "# File paths\n",
    "airport_hub_list_path = 'Data_final\\Airport_Hub_List.csv'\n",
    "flight_delays_directory = 'Flight_delays'\n",
    "output_directory = 'Flight_delays\\csv\\output_matched_APRT'\n",
    "\n",
    "# Load the Airport Hub List\n",
    "airport_hub_list_df = pd.read_csv(airport_hub_list_path)\n",
    "\n",
    "# Ensure the ARPT_ID column exists\n",
    "if 'ARPT_ID' not in airport_hub_list_df.columns:\n",
    "    raise KeyError(\"The column 'ARPT_ID' does not exist in Airport_Hub_List.csv.\")\n",
    "\n",
    "# Get the list of ARPT_IDs\n",
    "arpt_ids = airport_hub_list_df['ARPT_ID'].unique()\n",
    "\n",
    "# Iterate through each CSV file in the Flight_Delays directory\n",
    "for file in os.listdir(flight_delays_directory):\n",
    "    if file.endswith('.csv'):  # Process only CSV files\n",
    "        file_path = os.path.join(flight_delays_directory, file)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Filter rows where Origin or Dest match any ARPT_ID\n",
    "        filtered_df = df[(df['Origin'].isin(arpt_ids)) & (df['Dest'].isin(arpt_ids))]\n",
    "        \n",
    "        # Save the filtered DataFrame to the output directory\n",
    "        filtered_file_path = os.path.join(output_directory, file)\n",
    "        filtered_df.to_csv(filtered_file_path, index=False)\n",
    "        \n",
    "        print(f\"Filtered file: {file} (saved to {filtered_file_path})\")\n",
    "\n",
    "# Summary message\n",
    "print(f\"All CSV files in the Flight_Delays directory have been filtered and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87e6b68-bbde-45aa-b2bd-10396d8dbb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_1.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_10.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_11.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_12.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_2.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_3.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_4.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_5.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_6.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_7.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_8.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_9.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_1.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_10.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_11.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_12.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_2.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_3.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_4.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_5.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_6.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_7.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_8.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_9.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_1.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_10.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_11.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_12.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_2.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_3.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_4.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_5.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_6.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_7.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_8.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_9.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_1.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_10.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_11.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_12.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_2.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_3.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_4.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_5.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_6.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_7.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_8.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_9.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_10.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_11.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_2.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_3.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_4.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_5.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_6.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_7.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_8.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_9.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_1.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_2.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_3.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_4.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_5.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_6.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_7.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_8.csv\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_9.csv\n",
      "All CSV files in the folder have been updated.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Update columns CancellationCode -> replaces blank/NaN with \"Z\". \n",
    "    Columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraftDelay -> replaces blank/NaN with 0 \"\"\"\n",
    "\n",
    "# Path to the folder containing the CSV files\n",
    "folder_path = 'Flight_delays\\csv\\output_matched_APRT'\n",
    "\n",
    "# List of delay columns to update\n",
    "delay_columns = [\n",
    "    'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay'\n",
    "]\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):  # Process only CSV files\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Update the 'CancellationCode' column\n",
    "        if 'CancellationCode' in df.columns:\n",
    "            df['CancellationCode'].fillna('Z', inplace=True)\n",
    "            df['CancellationCode'].replace('', 'Z', inplace=True)\n",
    "\n",
    "        # Update delay columns with 0 for blanks or NaNs\n",
    "        for column in delay_columns:\n",
    "            if column in df.columns:\n",
    "                df[column].fillna(0, inplace=True)\n",
    "                df[column].replace('', 0, inplace=True)\n",
    "        \n",
    "        # Save the updated CSV file\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f\"Updated {file_name}\")\n",
    "\n",
    "print(\"All CSV files in the folder have been updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf56e88f-c2a9-4f03-beb1-88f866303a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_1.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_10.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_11.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_12.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_2.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_3.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_4.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_5.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_6.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_7.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_8.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_9.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_1.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_10.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_11.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_12.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_2.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_3.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_4.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_5.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_6.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_7.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_8.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_9.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_1.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_10.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_11.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_12.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_2.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_3.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_4.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_5.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_6.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_7.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_8.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_9.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_1.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_10.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_11.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_12.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_2.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_3.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_4.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_5.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_6.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_7.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_8.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_9.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_10.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_11.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_2.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_3.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_4.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_5.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_6.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_7.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_8.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_9.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_1.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_2.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_3.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_4.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_5.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_6.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_7.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_8.csv successfully and saved to output folder.\n",
      "Updated On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_9.csv successfully and saved to output folder.\n"
     ]
    }
   ],
   "source": [
    "# Data Engineering for flight delay data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the folder path containing the flight delay CSV files\n",
    "flight_delay_folder = 'Flight_delays\\csv\\output_matched_APRT\"\n",
    "output_folder = 'Flight_delays\\Data_engineered\"\n",
    "\n",
    "# Season mapping\n",
    "season_mapping = {'Winter': 1, 'Spring': 2, 'Summer': 3, 'Fall': 4}\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(flight_delay_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(flight_delay_folder, filename)\n",
    "\n",
    "        # Read the CSV file\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure required columns are present\n",
    "        required_columns = [\n",
    "            \"DepDelayMinutes\", \"ArrDelayMinutes\", \"CancellationCode\", \n",
    "            \"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \n",
    "            \"LateAircraftDelay\", \"Origin\", \"Dest\", \"Operating_Airline \", \"FlightDate\"\n",
    "        ]\n",
    "        if all(col in df.columns for col in required_columns):\n",
    "\n",
    "            # Create the 'Weather_Delayed_Departure' column\n",
    "            df[\"Weather_Delayed_Departure\"] = df.apply(\n",
    "                lambda x: 1 if x[\"DepDelayMinutes\"] > 15 and x[\"WeatherDelay\"] > 0 else 0, axis=1\n",
    "            )\n",
    "\n",
    "            # Create the 'Weather_Delayed_Arrival' column\n",
    "            df[\"Weather_Delayed_Arrival\"] = df.apply(\n",
    "                lambda x: 1 if x[\"ArrDelayMinutes\"] > 15 and x[\"WeatherDelay\"] > 0 else 0, axis=1\n",
    "            )\n",
    "\n",
    "            # Create the 'Delayed_Departure' column\n",
    "            df[\"Delayed_Departure\"] = df[\"DepDelayMinutes\"].apply(lambda x: 1 if x > 15 else 0)\n",
    "\n",
    "            # Create the 'Delayed_Arrival' column\n",
    "            df[\"Delayed_Arrival\"] = df[\"ArrDelayMinutes\"].apply(lambda x: 1 if x > 15 else 0)\n",
    "\n",
    "            # Create the 'Weather_Cancellation' column\n",
    "            df[\"Weather_Cancellation\"] = df[\"CancellationCode\"].apply(lambda x: 1 if x == \"B\" else 0)\n",
    "\n",
    "            # Create the 'Total_Delayed' column\n",
    "            df[\"Total_Delayed\"] = df[[\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\"]].applymap(lambda x: 1 if x > 0 else 0).sum(axis=1)\n",
    "\n",
    "            # Create the 'Total_Cancellation' column\n",
    "            df[\"Total_Cancellation\"] = df[\"CancellationCode\"].apply(lambda x: 1 if x in [\"A\", \"B\", \"C\", \"D\"] else 0)\n",
    "\n",
    "            # Add 'Month' column\n",
    "            df[\"Month\"] = pd.to_datetime(df[\"FlightDate\"], errors='coerce').dt.month\n",
    "\n",
    "            # Add 'Season' column\n",
    "            df[\"Season\"] = df[\"Month\"].apply(lambda x: 'Winter' if x in [12, 1, 2] else \\\n",
    "                                               'Spring' if x in [3, 4, 5] else \\\n",
    "                                               'Summer' if x in [6, 7, 8] else 'Fall')\n",
    "            df[\"Season\"] = df[\"Season\"].map(season_mapping)\n",
    "\n",
    "            # Save the updated DataFrame to the output folder\n",
    "            output_file_path = os.path.join(output_folder, filename)\n",
    "            try:\n",
    "                df.to_csv(output_file_path, index=False)\n",
    "                print(f\"Updated {filename} successfully and saved to output folder.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"Skipping {filename} - required columns not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0195d976-63fa-432f-9ddb-8d27851fdf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_1.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_10.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_11.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_12.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_2.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_3.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_4.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_5.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_6.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_7.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_8.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_9.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_1.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_10.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_11.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_12.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_2.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_3.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_4.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_5.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_6.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_7.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_8.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2020_9.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_1.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_10.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_11.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_12.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_2.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_3.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_4.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_5.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_6.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_7.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_8.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2021_9.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_1.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_10.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_11.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_12.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_2.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_3.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_4.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_5.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_6.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_7.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_8.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2022_9.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_1.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_10.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_11.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_12.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_2.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_3.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_4.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_5.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_6.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_7.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_8.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2023_9.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_1.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_2.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_3.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_4.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_5.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_6.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_7.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_8.csv\n",
      "Processing file: On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2024_9.csv\n",
      "Merging and cleaning completed. Updated files are saved in the output folder.\n"
     ]
    }
   ],
   "source": [
    "# Merge Weather data and flight delay data based on Origin Airports\n",
    "# Define the paths\n",
    "flight_delay_folder = 'Flight_delays\\Data_engineered\\archive\"\n",
    "weather_data_path = 'Merged_Weather_Data_Completed.csv\"\n",
    "output_folder = 'Flight_delays\\Data_engineered\\Origin_merge\"\n",
    "\n",
    "# Load the Weather Data.csv\n",
    "weather_data = pd.read_csv(weather_data_path)\n",
    "\n",
    "# Convert date to consistent format\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "\n",
    "# Process each file in the flight delay folder\n",
    "for file in os.listdir(flight_delay_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(flight_delay_folder, file)\n",
    "\n",
    "        # Load flight delay data\n",
    "        flight_data = pd.read_csv(file_path)\n",
    "        print(f\"Processing file: {file}\")\n",
    "\n",
    "        # Convert FlightDate to datetime\n",
    "        flight_data['FlightDate'] = pd.to_datetime(flight_data['FlightDate'])\n",
    "\n",
    "        # Merge with weather data\n",
    "        merged_data = pd.merge(flight_data, weather_data,\n",
    "                               left_on=['FlightDate', 'Origin'],\n",
    "                               right_on=['date', 'ARPT_ID'],\n",
    "                               how='inner')\n",
    "\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        merged_data_cleaned = merged_data.drop(columns=[\n",
    "            'latitude', 'longitude', 'weather_code', 'temperature_2m_max', 'temperature_2m_min',\n",
    "            'precipitation_sum', 'snowfall_sum', 'precipitation_hours', 'wind_speed_10m_max',\n",
    "            'wind_gusts_10m_max', 'wind_direction_10m_dominant', 'Quarter', 'Flight_Number_Operating_Airline',\n",
    "            'OriginCityName', 'DestCityName', 'CRSDepTime', 'DepTime',\n",
    "            'DepDelay', 'DepDelayMinutes', 'CRSArrTime', 'ArrTime', 'ArrDelay', 'ArrDelayMinutes',\n",
    "            'Cancelled', 'CancellationCode', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay',\n",
    "            'LateAircraftDelay'\n",
    "        ], errors='ignore')\n",
    "\n",
    "        # Create output file name\n",
    "        output_file_name = f\"Updated{file[-11:]}\"\n",
    "        output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "        # Save the merged and cleaned data\n",
    "        merged_data_cleaned.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Merging and cleaning completed. Updated files are saved in the output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ad1cb3a-b8f8-4bba-9d71-00ee3eb3c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and saving completed. Updated files are saved in the output folder.\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to add \"Origin_\" to differentiate weather from origin airports\n",
    "# Define the paths\n",
    "flight_delay_folder = 'Flight_delays\\Data_engineered\\Origin_merge\"\n",
    "output_folder = 'Flight_delays\\Data_engineered\\Origin_merge\\Origin_renamed\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each file in the flight delay folder\n",
    "for file in os.listdir(flight_delay_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(flight_delay_folder, file)\n",
    "\n",
    "        # Load flight delay data\n",
    "        try:\n",
    "            flight_data = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        try:\n",
    "            flight_data_cleaned = flight_data.drop(columns=['date', 'ARPT_ID', 'high_delay_likelihood'], errors='ignore')\n",
    "        except Exception as e:\n",
    "            print(f\"Error dropping columns in {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Rename columns\n",
    "        rename_columns = {\n",
    "            'extreme_heat': 'Origin_Extreme Heat',\n",
    "            'extreme_cold': 'Origin_Extreme Cold',\n",
    "            'severe_cold': 'Origin_Severe Cold',\n",
    "            'light_precipitation': 'Origin_Light Precipitation',\n",
    "            'moderate_precipitation': 'Origin_Moderate Precipitation',\n",
    "            'heavy_precipitation': 'Origin_Heavy Precipitation',\n",
    "            'freezing_precipitation': 'Origin_Freezing Precipitation',\n",
    "            'strong_winds': 'Origin_Strong Winds',\n",
    "            'severe_winds': 'Origin_Severe Winds'\n",
    "        }\n",
    "        try:\n",
    "            flight_data_cleaned = flight_data_cleaned.rename(columns=rename_columns)\n",
    "        except Exception as e:\n",
    "            print(f\"Error renaming columns in {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Create output file name with prefix 'Updated_' and last 7 characters of the original file name\n",
    "        output_file_name = f\"Updated{file[-11:]}\"\n",
    "        output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "        # Save the cleaned data to a new CSV file\n",
    "        try:\n",
    "            flight_data_cleaned.to_csv(output_file_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {output_file_name}: {e}\")\n",
    "\n",
    "print(\"Cleaning and saving completed. Updated files are saved in the output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1165450a-0866-469b-afc4-b6b56490fa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Updated_2019_1.csv\n",
      "Processing file: Updated_2019_10.csv\n",
      "Processing file: Updated_2019_11.csv\n",
      "Processing file: Updated_2019_12.csv\n",
      "Processing file: Updated_2019_2.csv\n",
      "Processing file: Updated_2019_3.csv\n",
      "Processing file: Updated_2019_4.csv\n",
      "Processing file: Updated_2019_5.csv\n",
      "Processing file: Updated_2019_6.csv\n",
      "Processing file: Updated_2019_7.csv\n",
      "Processing file: Updated_2019_8.csv\n",
      "Processing file: Updated_2019_9.csv\n",
      "Processing file: Updated_2020_1.csv\n",
      "Processing file: Updated_2020_10.csv\n",
      "Processing file: Updated_2020_11.csv\n",
      "Processing file: Updated_2020_12.csv\n",
      "Processing file: Updated_2020_2.csv\n",
      "Processing file: Updated_2020_3.csv\n",
      "Processing file: Updated_2020_4.csv\n",
      "Processing file: Updated_2020_5.csv\n",
      "Processing file: Updated_2020_6.csv\n",
      "Processing file: Updated_2020_7.csv\n",
      "Processing file: Updated_2020_8.csv\n",
      "Processing file: Updated_2020_9.csv\n",
      "Processing file: Updated_2021_1.csv\n",
      "Processing file: Updated_2021_10.csv\n",
      "Processing file: Updated_2021_11.csv\n",
      "Processing file: Updated_2021_12.csv\n",
      "Processing file: Updated_2021_2.csv\n",
      "Processing file: Updated_2021_3.csv\n",
      "Processing file: Updated_2021_4.csv\n",
      "Processing file: Updated_2021_5.csv\n",
      "Processing file: Updated_2021_6.csv\n",
      "Processing file: Updated_2021_7.csv\n",
      "Processing file: Updated_2021_8.csv\n",
      "Processing file: Updated_2021_9.csv\n",
      "Processing file: Updated_2022_1.csv\n",
      "Processing file: Updated_2022_10.csv\n",
      "Processing file: Updated_2022_11.csv\n",
      "Processing file: Updated_2022_12.csv\n",
      "Processing file: Updated_2022_2.csv\n",
      "Processing file: Updated_2022_3.csv\n",
      "Processing file: Updated_2022_4.csv\n",
      "Processing file: Updated_2022_5.csv\n",
      "Processing file: Updated_2022_6.csv\n",
      "Processing file: Updated_2022_7.csv\n",
      "Processing file: Updated_2022_8.csv\n",
      "Processing file: Updated_2022_9.csv\n",
      "Processing file: Updated_2023_1.csv\n",
      "Processing file: Updated_2023_10.csv\n",
      "Processing file: Updated_2023_11.csv\n",
      "Processing file: Updated_2023_12.csv\n",
      "Processing file: Updated_2023_2.csv\n",
      "Processing file: Updated_2023_3.csv\n",
      "Processing file: Updated_2023_4.csv\n",
      "Processing file: Updated_2023_5.csv\n",
      "Processing file: Updated_2023_6.csv\n",
      "Processing file: Updated_2023_7.csv\n",
      "Processing file: Updated_2023_8.csv\n",
      "Processing file: Updated_2023_9.csv\n",
      "Processing file: Updated_2024_1.csv\n",
      "Processing file: Updated_2024_2.csv\n",
      "Processing file: Updated_2024_3.csv\n",
      "Processing file: Updated_2024_4.csv\n",
      "Processing file: Updated_2024_5.csv\n",
      "Processing file: Updated_2024_6.csv\n",
      "Processing file: Updated_2024_7.csv\n",
      "Processing file: Updated_2024_8.csv\n",
      "Processing file: Updated_2024_9.csv\n",
      "Merging and cleaning completed. Updated files are saved in the output folder.\n"
     ]
    }
   ],
   "source": [
    "# Drop unneeded columns to reduce file size\n",
    "# Define the paths\n",
    "flight_delay_folder = 'Flight_delays\\Data_engineered\\Origin\"\n",
    "weather_data_path = 'Data_final\\Merged_Weather_Data_Completed.csv\"\n",
    "output_folder = 'Flight_delays\\Data_engineered\\Dest_merged\"\n",
    "\n",
    "# Load the Weather Data.csv\n",
    "weather_data = pd.read_csv(weather_data_path)\n",
    "\n",
    "# Convert date to consistent format\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'])\n",
    "\n",
    "# Process each file in the flight delay folder\n",
    "for file in os.listdir(flight_delay_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(flight_delay_folder, file)\n",
    "\n",
    "        # Load flight delay data\n",
    "        flight_data = pd.read_csv(file_path)\n",
    "        print(f\"Processing file: {file}\")\n",
    "\n",
    "        # Convert FlightDate to datetime\n",
    "        flight_data['FlightDate'] = pd.to_datetime(flight_data['FlightDate'])\n",
    "\n",
    "        # Merge with weather data\n",
    "        merged_data = pd.merge(flight_data, weather_data,\n",
    "                               left_on=['FlightDate', 'Dest'],\n",
    "                               right_on=['date', 'ARPT_ID'],\n",
    "                               how='inner')\n",
    "\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        merged_data_cleaned = merged_data.drop(columns=[\n",
    "            'latitude', 'longitude', 'weather_code', 'temperature_2m_max', 'temperature_2m_min',\n",
    "            'precipitation_sum', 'snowfall_sum', 'precipitation_hours', 'wind_speed_10m_max',\n",
    "            'wind_gusts_10m_max', 'wind_direction_10m_dominant', 'Quarter', 'Flight_Number_Operating_Airline',\n",
    "            'OriginCityName', 'DestCityName', 'CRSDepTime', 'DepTime',\n",
    "            'DepDelay', 'DepDelayMinutes', 'CRSArrTime', 'ArrTime', 'ArrDelay', 'ArrDelayMinutes',\n",
    "            'Cancelled', 'CancellationCode', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay',\n",
    "            'LateAircraftDelay'\n",
    "        ], errors='ignore')\n",
    "\n",
    "        # Create output file name\n",
    "        output_file_name = f\"Updated{file[-11:]}\"\n",
    "        output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "        # Save the merged and cleaned data\n",
    "        merged_data_cleaned.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Merging and cleaning completed. Updated files are saved in the output folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c65a9-4ac7-4a62-a1cd-151167cb0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean unneeded columns resulting from join\n",
    "# Define the paths\n",
    "flight_delay_folder = 'Flight_delays\\Data_engineered\\Dest_merged\"\n",
    "output_folder = 'Flight_delays\\Data_engineered\\Flight_delay_Weather_Data\"\n",
    "\n",
    "# Process each file in the flight delay folder\n",
    "for file in os.listdir(flight_delay_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(flight_delay_folder, file)\n",
    "\n",
    "        # Load flight delay data\n",
    "        try:\n",
    "            flight_data = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        flight_data_cleaned = flight_data.drop(columns=['date', 'ARPT_ID'], errors='ignore')\n",
    "\n",
    "        # Rename columns\n",
    "        rename_columns = {\n",
    "            'extreme_heat': 'Dest_Extreme Heat',\n",
    "            'extreme_cold': 'Dest_Extreme Cold',\n",
    "            'severe_cold': 'Dest_Severe Cold',\n",
    "            'light_precipitation': 'Dest_Light Precipitation',\n",
    "            'moderate_precipitation': 'Dest_Moderate Precipitation',\n",
    "            'heavy_precipitation': 'Dest_Heavy Precipitation',\n",
    "            'freezing_precipitation': 'Dest_Freezing Precipitation',\n",
    "            'strong_winds': 'Dest_Strong Winds',\n",
    "            'severe_winds': 'Dest_Severe Winds'\n",
    "        }\n",
    "        flight_data_cleaned = flight_data_cleaned.rename(columns=rename_columns)\n",
    "\n",
    "        # Drop additional columns if present\n",
    "        flight_data_cleaned = flight_data_cleaned.drop(columns=['high_delay_likelihood'], errors='ignore')\n",
    "\n",
    "        # Create output file name with prefix 'Updated_'\n",
    "        output_file_name = f\"{file}\"\n",
    "        output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "        # Save the cleaned data to a new CSV file\n",
    "        try:\n",
    "            flight_data_cleaned.to_csv(output_file_path, index=False)\n",
    "            print(f\"Saved: {output_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {output_file_name}: {e}\")\n",
    "\n",
    "print(\"Cleaning and saving completed. Updated files are saved in the output folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660af2f5-cb13-4bd0-a77f-30b671372cf2",
   "metadata": {},
   "source": [
    "## Load data to Postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae6cab1-e2eb-493c-a268-90fd67939a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL database successfully!\n",
      "Successfully loaded Updated2019_10.csv into the Updated2019_10 table.\n",
      "Successfully loaded Updated2019_11.csv into the Updated2019_11 table.\n",
      "Successfully loaded Updated2019_12.csv into the Updated2019_12 table.\n",
      "Successfully loaded Updated2020_10.csv into the Updated2020_10 table.\n",
      "Successfully loaded Updated2020_11.csv into the Updated2020_11 table.\n",
      "Successfully loaded Updated2020_12.csv into the Updated2020_12 table.\n",
      "Successfully loaded Updated2021_10.csv into the Updated2021_10 table.\n",
      "Successfully loaded Updated2021_11.csv into the Updated2021_11 table.\n",
      "Successfully loaded Updated2021_12.csv into the Updated2021_12 table.\n",
      "Successfully loaded Updated2022_10.csv into the Updated2022_10 table.\n",
      "Successfully loaded Updated2022_11.csv into the Updated2022_11 table.\n",
      "Successfully loaded Updated2022_12.csv into the Updated2022_12 table.\n",
      "Successfully loaded Updated2023_10.csv into the Updated2023_10 table.\n",
      "Successfully loaded Updated2023_11.csv into the Updated2023_11 table.\n",
      "Successfully loaded Updated2023_12.csv into the Updated2023_12 table.\n",
      "Successfully loaded Updated_2019_1.csv into the Updated_2019_1 table.\n",
      "Successfully loaded Updated_2019_2.csv into the Updated_2019_2 table.\n",
      "Successfully loaded Updated_2019_3.csv into the Updated_2019_3 table.\n",
      "Successfully loaded Updated_2019_4.csv into the Updated_2019_4 table.\n",
      "Successfully loaded Updated_2019_5.csv into the Updated_2019_5 table.\n",
      "Successfully loaded Updated_2019_6.csv into the Updated_2019_6 table.\n",
      "Successfully loaded Updated_2019_7.csv into the Updated_2019_7 table.\n",
      "Successfully loaded Updated_2019_8.csv into the Updated_2019_8 table.\n",
      "Successfully loaded Updated_2019_9.csv into the Updated_2019_9 table.\n",
      "Successfully loaded Updated_2020_1.csv into the Updated_2020_1 table.\n",
      "Successfully loaded Updated_2020_2.csv into the Updated_2020_2 table.\n",
      "Successfully loaded Updated_2020_3.csv into the Updated_2020_3 table.\n",
      "Successfully loaded Updated_2020_4.csv into the Updated_2020_4 table.\n",
      "Successfully loaded Updated_2020_5.csv into the Updated_2020_5 table.\n",
      "Successfully loaded Updated_2020_6.csv into the Updated_2020_6 table.\n",
      "Successfully loaded Updated_2020_7.csv into the Updated_2020_7 table.\n",
      "Successfully loaded Updated_2020_8.csv into the Updated_2020_8 table.\n",
      "Successfully loaded Updated_2020_9.csv into the Updated_2020_9 table.\n",
      "Successfully loaded Updated_2021_1.csv into the Updated_2021_1 table.\n",
      "Successfully loaded Updated_2021_2.csv into the Updated_2021_2 table.\n",
      "Successfully loaded Updated_2021_3.csv into the Updated_2021_3 table.\n",
      "Successfully loaded Updated_2021_4.csv into the Updated_2021_4 table.\n",
      "Successfully loaded Updated_2021_5.csv into the Updated_2021_5 table.\n",
      "Successfully loaded Updated_2021_6.csv into the Updated_2021_6 table.\n",
      "Successfully loaded Updated_2021_7.csv into the Updated_2021_7 table.\n",
      "Successfully loaded Updated_2021_8.csv into the Updated_2021_8 table.\n",
      "Successfully loaded Updated_2021_9.csv into the Updated_2021_9 table.\n",
      "Successfully loaded Updated_2022_1.csv into the Updated_2022_1 table.\n",
      "Successfully loaded Updated_2022_2.csv into the Updated_2022_2 table.\n",
      "Successfully loaded Updated_2022_3.csv into the Updated_2022_3 table.\n",
      "Successfully loaded Updated_2022_4.csv into the Updated_2022_4 table.\n",
      "Successfully loaded Updated_2022_5.csv into the Updated_2022_5 table.\n",
      "Successfully loaded Updated_2022_6.csv into the Updated_2022_6 table.\n",
      "Successfully loaded Updated_2022_7.csv into the Updated_2022_7 table.\n",
      "Successfully loaded Updated_2022_8.csv into the Updated_2022_8 table.\n",
      "Successfully loaded Updated_2022_9.csv into the Updated_2022_9 table.\n",
      "Successfully loaded Updated_2023_1.csv into the Updated_2023_1 table.\n",
      "Successfully loaded Updated_2023_2.csv into the Updated_2023_2 table.\n",
      "Successfully loaded Updated_2023_3.csv into the Updated_2023_3 table.\n",
      "Successfully loaded Updated_2023_4.csv into the Updated_2023_4 table.\n",
      "Successfully loaded Updated_2023_5.csv into the Updated_2023_5 table.\n",
      "Successfully loaded Updated_2023_6.csv into the Updated_2023_6 table.\n",
      "Successfully loaded Updated_2023_7.csv into the Updated_2023_7 table.\n",
      "Successfully loaded Updated_2023_8.csv into the Updated_2023_8 table.\n",
      "Successfully loaded Updated_2023_9.csv into the Updated_2023_9 table.\n",
      "Successfully loaded Updated_2024_1.csv into the Updated_2024_1 table.\n",
      "Successfully loaded Updated_2024_2.csv into the Updated_2024_2 table.\n",
      "Successfully loaded Updated_2024_3.csv into the Updated_2024_3 table.\n",
      "Successfully loaded Updated_2024_4.csv into the Updated_2024_4 table.\n",
      "Successfully loaded Updated_2024_5.csv into the Updated_2024_5 table.\n",
      "Successfully loaded Updated_2024_6.csv into the Updated_2024_6 table.\n",
      "Successfully loaded Updated_2024_7.csv into the Updated_2024_7 table.\n",
      "Successfully loaded Updated_2024_8.csv into the Updated_2024_8 table.\n",
      "Successfully loaded Updated_2024_9.csv into the Updated_2024_9 table.\n",
      "Data loading complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# PostgreSQL connection details\n",
    "host = \"localhost\"        \n",
    "port = \"5432\"              \n",
    "database = \"Project_4_Data\"  \n",
    "user = \"postgres\"         \n",
    "password = \"postgres\" \n",
    "\n",
    "# Directory containing your CSV files\n",
    "csv_directory = 'Flight_delay_Weather_Data\"\n",
    "\n",
    "# Create a connection to PostgreSQL using SQLAlchemy\n",
    "try:\n",
    "    engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\")\n",
    "    print(\"Connected to PostgreSQL database successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to database: {e}\")\n",
    "\n",
    "# Iterate through each CSV file in the directory\n",
    "for file in os.listdir(csv_directory):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(csv_directory, file)\n",
    "        \n",
    "        # Extract table name from the CSV file name\n",
    "        table_name = os.path.splitext(file)[0]\n",
    "        \n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Load DataFrame to PostgreSQL\n",
    "        try:\n",
    "            df.to_sql(table_name, engine, if_exists=\"replace\", index=False)\n",
    "            print(f\"Successfully loaded {file} into the {table_name} table.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "# Close the connection\n",
    "engine.dispose()\n",
    "print(\"Data loading complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202429a9-2b78-49b6-92a7-6f4af6150d5e",
   "metadata": {},
   "source": [
    "## Extract data table from Postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33b5c39-019e-46cd-ba77-a3c1862c5506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database.\n",
      "Table 'airport_hubs' exported to 'D:\\_Bootcamp\\_Project4\\Git\\Git2\\sql_output.csv'.\n",
      "Database connection closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\penguin\\AppData\\Local\\Temp\\ipykernel_15164\\4165947174.py:25: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Database connection details\n",
    "host = \"localhost\"\n",
    "database = \"Project_4_Data\"\n",
    "user = \"postgres\"\n",
    "password = \"postgres\"\n",
    "table_name = \"airport_hubs\"  # This was reused to export other tables\n",
    "output_file = r\"D:\\_Bootcamp\\_Project4\\Git\\Git2\\sql_output.csv\"\n",
    "\n",
    "try:\n",
    "    # Establish the connection\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        database=database,\n",
    "        user=user,\n",
    "        password=password\n",
    "    )\n",
    "    print(\"Connected to the database.\")\n",
    "\n",
    "    # Create a SQL query to select all data from the table\n",
    "    query = f\"SELECT * FROM {table_name};\"\n",
    "\n",
    "    # Use pandas to execute the query and load the data into a DataFrame\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    # Export the DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Table '{table_name}' exported to '{output_file}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ee091-a4a5-417c-9b87-f784ee1a8d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
